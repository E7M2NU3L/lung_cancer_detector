{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Importing the necessary libraries for dataset loading, manipulation and building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step -2 Preparing the dataset from the directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148\n"
     ]
    }
   ],
   "source": [
    "# creating paths for the urls\n",
    "train_dir = \"../datasets/TrainingDataset/\"\n",
    "test_dir = \"../datasets/TestingDataset/\"\n",
    "sample_image = cv2.imread(os.path.join(train_dir, \"Covid/1-s2.0-S0140673620303706-fx1_lrg.jpg\"))\n",
    "\n",
    "# getting the sample image info\n",
    "image_size = sample_image.shape\n",
    "print(image_size[0])\n",
    "\n",
    "image_size = (180, 180, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareData:\n",
    "    def __init__(self, directory_path : str, image_size : tuple, batch_size : int) -> DataLoader:\n",
    "        self.directory_path = directory_path\n",
    "        self.image_size = image_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def prepare_dataset(self):\n",
    "        transform = transforms.Compose([\n",
    "                transforms.Resize((image_size[0], image_size[1])),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        \n",
    "        dataset = datasets.ImageFolder(\n",
    "            root=self.directory_path,\n",
    "            transform=transform\n",
    "        )\n",
    "\n",
    "        loaded_data = DataLoader(\n",
    "                dataset,\n",
    "                batch_size=self.batch_size,\n",
    "                shuffle=True,\n",
    "                num_workers=4\n",
    "            )\n",
    "        \n",
    "        return loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_instance = PrepareData(directory_path=test_dir, batch_size=8, image_size=image_size)\n",
    "train_dataset_instance = PrepareData(directory_path=train_dir, batch_size=8, image_size=image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________Prepating the train dataset__________\n",
      "Process completed successfully!\n",
      "\n",
      "\n",
      "________Prepating the test dataset__________\n",
      "Process completed successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"________Prepating the train dataset__________\")\n",
    "train_loader = train_dataset_instance.prepare_dataset()\n",
    "print(\"Process completed successfully!\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"________Prepating the test dataset__________\")\n",
    "test_loader = test_dataset_instance.prepare_dataset()\n",
    "print(\"Process completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step - 3 Building the CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # Output: (90, 90, 32)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # Output: (45, 45, 64)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)  # Output: (22, 22, 128)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)  # Output: (11, 11, 256)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(256 * 11 * 11, 512)\n",
    "        self.relu_fc1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(self.relu2(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(self.relu3(self.bn3(self.conv3(x))))\n",
    "        x = self.pool4(self.relu4(self.bn4(self.conv4(x))))\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        \n",
    "        x = self.dropout(self.relu_fc1(self.fc1(x)))\n",
    "        x = self.fc2(x)  # For binary classification\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device: \",device)\n",
    "\n",
    "model = CNN(num_classes=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step - 4 Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 2.0862\n",
      "Epoch [2/10], Loss: 3.2926\n",
      "Epoch [3/10], Loss: 1.2922\n",
      "Epoch [4/10], Loss: 0.9662\n",
      "Epoch [5/10], Loss: 0.9302\n",
      "Epoch [6/10], Loss: 0.1949\n",
      "Epoch [7/10], Loss: 0.0000\n",
      "Epoch [8/10], Loss: 1.3325\n",
      "Epoch [9/10], Loss: 4.1461\n",
      "Epoch [10/10], Loss: 0.2482\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step - 5 Evaluating the Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 98.00%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on test set: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step - 6 Model Deployment as a pytorch file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../models/covid_detector.pth\"\n",
    "torch.save(model.state_dict(), output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU()\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU()\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu4): ReLU()\n",
      "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=30976, out_features=512, bias=True)\n",
      "  (relu_fc1): ReLU()\n",
      "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "model is packaged and loaded perfectly...\n"
     ]
    }
   ],
   "source": [
    "# checking the model's loading and evaluation\n",
    "\n",
    "model.load_state_dict(torch.load(output_dir))\n",
    "print(model.eval())\n",
    "print(\"model is packaged and loaded perfectly...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing of the Model's standalone performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((180, 180)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "# Load and transform the image\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # Ensure RGB format\n",
    "    image = transform(image)  # Apply transformations\n",
    "    image = image.unsqueeze(0)  # Add batch dimension\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Covid\n"
     ]
    }
   ],
   "source": [
    "# Define class labels\n",
    "class_labels = [\"Covid\", \"Normal\"]\n",
    "\n",
    "def predict_image(image_path):\n",
    "    image = preprocess_image(image_path)\n",
    "\n",
    "    # Forward pass through the model\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        predicted_class = torch.argmax(output, dim=1).item()\n",
    "\n",
    "    return class_labels[predicted_class]\n",
    "\n",
    "# Example usage\n",
    "image_path = \"../datasets/TestingDataset/Covid/1-s2.0-S0140673620303706-fx1_lrg.jpg\"  # Replace with your image file\n",
    "prediction = predict_image(image_path)\n",
    "print(f\"Prediction: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
